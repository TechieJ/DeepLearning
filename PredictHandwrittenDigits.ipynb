{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 10s 170us/sample - loss: 0.2598 - accuracy: 0.9233\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 0.1064 - accuracy: 0.9669\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0730 - accuracy: 0.9770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a91314b148>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist # 28 * 28 images of hand written digits 0-9\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = tf.keras.utils.normalize(X_train, axis = 1)\n",
    "X_test = tf.keras.utils.normalize(X_test, axis = 1)\n",
    "\n",
    "model = tf.keras.models.Sequential() # simple model\n",
    "model.add( tf.keras.layers.Flatten() ) #first layer - input layer. Flatten layer makes our work easy\n",
    "model.add( tf.keras.layers.Dense( 128, activation = tf.nn.relu ) ) # Hidden layer - 128 neurons\n",
    "model.add( tf.keras.layers.Dense( 128, activation = tf.nn.relu ) ) # Hidden layer - 128 neurons\n",
    "model.add( tf.keras.layers.Dense( 10, activation = tf.nn.softmax ) ) # Output layer - no of neurons is no of classifications.\n",
    "# Output layer needs probability distribution and softmax is good. we dont want to be relu\n",
    "# Training of model\n",
    "model.compile(optimizer = \"adam\", # It is default go to. you can use gradient descent. it is most complesx part of NN. \n",
    "              loss = 'sparse_categorical_crossentropy', # It is most popular. In case cats/dogs you can use binary\n",
    "              # Loss is degree of error, NN does not try to maximize the accuracy, it always tries to minimize the loss.\n",
    "              metrics = [\"accuracy\"])\n",
    "model.fit(X_train, y_train, epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 92us/sample - loss: 0.0885 - accuracy: 0.9722\n",
      "0.08852266122354195 0.9722\n"
     ]
    }
   ],
   "source": [
    "# NN are great at fitting and they can overfit. Idea is model has to be generalized.\n",
    "# Model learns patterns and actual attributes to what makes it 4 or 8 rather than memorizing all the samples you have passed.\n",
    "\n",
    "# what we always do is calculate the validation loss and validation accuracy\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test)\n",
    "print( val_loss, val_acc )\n",
    "\n",
    "# If you comare with the epoch 3 result, the loss is now slightly higher and accuracy is slightly lower. You should expect this.\n",
    "# What you should not see is too close or toooo much of a delta. If there is a big gap then you most probably overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\erjai\\anaconda3\\envs\\ineuron1\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: epic_num_reader.model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save a model and load a model\n",
    "model.save(\"epic_num_reader.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model(\"epic_num_reader.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = new_model.predict(X_test)\n",
    "# Input samples. It could be:\n",
    "#      - A Numpy array (or array-like), or a list of arrays\n",
    "#        (in case the model has multiple inputs).\n",
    "#      - A TensorFlow tensor, or a list of tensors\n",
    "#        (in case the model has multiple inputs).\n",
    "#      - A `tf.data` dataset.\n",
    "#      - A generator or `keras.utils.Sequence` instance.\n",
    "#      A more detailed description of unpacking behavior for iterator types\n",
    "#      (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
    "#      for iterator-like inputs` section of `Model.fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.94362325e-07 7.22985760e-06 1.32233836e-05 ... 9.97821808e-01\n",
      "  1.17470017e-06 1.45484341e-06]\n",
      " [8.27611257e-10 4.30607543e-05 9.99950290e-01 ... 8.16647727e-09\n",
      "  2.29714715e-07 4.97211159e-13]\n",
      " [2.00160457e-07 9.99788463e-01 7.41721524e-05 ... 8.11870050e-05\n",
      "  3.27865018e-05 1.72570338e-07]\n",
      " ...\n",
      " [5.11621578e-10 2.49238195e-08 2.88825230e-09 ... 4.35513994e-06\n",
      "  2.00271779e-06 4.08717140e-04]\n",
      " [9.12313141e-08 4.10012717e-08 1.02024424e-08 ... 6.07244090e-07\n",
      "  3.99684533e-04 1.82267144e-08]\n",
      " [1.52494096e-07 1.22518884e-09 2.35106175e-08 ... 2.96939686e-12\n",
      "  3.49341548e-07 7.49449125e-09]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions) #not too friendly and these are probability distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.argmax(predictions[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow( X_train[0], cmap = plt.cm.binary )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00393124 0.02332955 0.02620568 0.02625207 0.17420356 0.17566281\n",
      "  0.28629534 0.05664824 0.51877786 0.71632322 0.77892406 0.89301644\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.05780486 0.06524513 0.16128198 0.22713296\n",
      "  0.22277047 0.32790981 0.36833534 0.3689874  0.34978968 0.32678448\n",
      "  0.368094   0.3747499  0.79066747 0.67980478 0.61494005 0.45002403\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.12250613 0.45858525 0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.32790981 0.36833534 0.3689874  0.34978968 0.32420121\n",
      "  0.15214552 0.17865984 0.25626376 0.1573102  0.12298801 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.04500225 0.4219755  0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.32790981 0.28826244 0.26543758 0.34149427 0.31128482\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.1541463  0.28272888 0.18358693 0.37314701\n",
      "  0.33153488 0.26569767 0.01601458 0.         0.05945042 0.19891229\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.0253731  0.00171577 0.22713296\n",
      "  0.33153488 0.11664776 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.20500962\n",
      "  0.33153488 0.24625638 0.00291174 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.01622378\n",
      "  0.24897876 0.32790981 0.10191096 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04586451 0.31235677 0.32757096 0.23335172 0.14931733 0.00129164\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.10498298 0.34940902 0.3689874  0.34978968 0.15370495\n",
      "  0.04089933 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06551419 0.27127137 0.34978968 0.32678448\n",
      "  0.245396   0.05882702 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.02333517 0.12857881 0.32549285\n",
      "  0.41390126 0.40743158 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.32161793\n",
      "  0.41390126 0.54251585 0.20001074 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06697006 0.18959827 0.25300993 0.32678448\n",
      "  0.41390126 0.45100715 0.00625034 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05110617 0.19182076 0.33339444 0.3689874  0.34978968 0.32678448\n",
      "  0.40899334 0.39653769 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.04117838 0.16813739\n",
      "  0.28960162 0.32790981 0.36833534 0.3689874  0.34978968 0.25961929\n",
      "  0.12760592 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.04431706 0.11961607 0.36545809 0.37314701\n",
      "  0.33153488 0.32790981 0.36833534 0.28877275 0.111988   0.00258328\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.05298497 0.42752138 0.4219755  0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.25273681 0.11646967 0.01312603 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.37491383 0.56222061\n",
      "  0.66525569 0.63253163 0.48748768 0.45852825 0.43408872 0.359873\n",
      "  0.17428513 0.01425695 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.92705966 0.82698729\n",
      "  0.74473314 0.63253163 0.4084877  0.24466922 0.22648107 0.02359823\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
